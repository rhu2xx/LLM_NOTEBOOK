{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0095599",
   "metadata": {},
   "source": [
    "# torch.scatter_reduce_ and torch.gather\n",
    "\n",
    "\n",
    "\n",
    "| Operation        | Direction | Meaning                                               |\n",
    "| ---------------- | --------- | ----------------------------------------------------- |\n",
    "| `gather`         | read      | “pull” data from positions in input                   |\n",
    "| `scatter_reduce` | write     | “push” data into positions of output (with reduction) |\n",
    "\n",
    "\n",
    "`torch.scatter_reduce(input, dim, index, src, reduce, *, include_self=True)`\n",
    "- goal: write (“scatter”) values into an output tensor at given indices, reducing if multiple writes go to the same spot.\n",
    "- `input`: base tensor to scatter into\n",
    "- `dim`: dimension to scatter along\n",
    "- `index`: where to write each element\n",
    "- `src`: what values to write\n",
    "> - `index` and `src` should all have the same number of dimensions. \n",
    "> - reduce argument (\"sum\", \"prod\", \"mean\", \"amax\", \"amin\").\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25eb9279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 10,  50,  40,   0],\n",
      "        [  0,  50, 130,  80]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "index = torch.tensor([[0, 1, 1, 2],\n",
    "                      [1, 2, 2, 3]])\n",
    "src = torch.tensor([[10, 20, 30, 40],\n",
    "                    [50, 60, 70, 80]])\n",
    "x = torch.zeros(2, 4, dtype = src.dtype)\n",
    "out = torch.scatter_reduce(x, dim=1, index=index, src=src, reduce='sum')\n",
    "print(out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc48619",
   "metadata": {},
   "source": [
    "`torch.gather(input, dim, index, *, sparse_grad=False, out=None)`\n",
    "- goal: Collect (“gather”) elements from a source tensor according to given indices.\n",
    "- `input` is the source tensor from which to gather values.\n",
    "- `dim` is the dimension along which to index.\n",
    "- `index` is a tensor containing the indices of the values to gather.\n",
    "> - `input` and `index` must have the same number of dimensions. \n",
    "> - `out` will have the same shape as `index`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e30f96f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[30, 20, 10],\n",
      "        [40, 60, 50]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.tensor([[10, 20, 30],\n",
    "                  [40, 50, 60]])  # shape (2,3)\n",
    "\n",
    "idx = torch.tensor([[2, 1, 0],\n",
    "                    [0, 2, 1]])   # shape (2,3)\n",
    "\n",
    "y = torch.gather(x, dim=1, index=idx)\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7cbf54",
   "metadata": {},
   "source": [
    "## Example: merge the kv cache\n",
    "\n",
    "Goal: Compute the cosine similarity between two groups of key caches (A and B), and group cache A based on the similarity scores with B. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5dc5ca09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac7a9804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 8,  3,  1,  4,  4],\n",
       "         [ 2,  4,  8,  6,  0],\n",
       "         [ 5,  5,  2,  1,  7],\n",
       "         [ 7,  5,  5,  2,  1]],\n",
       "\n",
       "        [[ 8,  4,  4,  2,  2],\n",
       "         [ 4,  3,  3,  1,  9],\n",
       "         [ 8,  1,  6,  3,  2],\n",
       "         [ 1,  4, 11,  3,  1]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "bsz, num_head, head_dim = 2, 4, 64\n",
    "A_len = 20\n",
    "B_len = 5\n",
    "\n",
    "A =  torch.rand((bsz, num_head, A_len, head_dim))\n",
    "B =  torch.rand((bsz, num_head, B_len, head_dim))\n",
    "\n",
    "# compute the cosine similarity between A and B\n",
    "A_norm = A.norm(dim=-1, keepdim=True)\n",
    "B_norm = B.norm(dim=-1, keepdim=True)\n",
    "similarity = (A @ B.transpose(-2, -1)) / (A_norm @ B_norm.transpose(-2, -1)) # [bsz, num_head, A_len, B_len]\n",
    "\n",
    "group_idx_per_A_val, group_idx_per_A_idx = similarity.max(dim = -1)\n",
    "\n",
    "# compute the per-group softmax over group_idx_per_A_val (grouped by group_idx_per_A_idx)\n",
    "# softmax: exp(i - max)/\\sum exp(j-max)\n",
    "## get the maximum per group\n",
    "group_max = torch.full((bsz, num_head, B_len), float('-inf'), dtype=B.dtype, device = B.device)\n",
    "group_max.scatter_reduce_(dim = 2, index = group_idx_per_A_idx, src = group_idx_per_A_val, reduce = 'amax', include_self=True) \n",
    "\n",
    "## compute the weight by softmax\n",
    "weight_per_A = group_max.gather(index = group_idx_per_A_idx, dim = 2) # [bsz, num_head, A_len]\n",
    "weight_per_A = torch.exp(group_idx_per_A_val - weight_per_A)\n",
    "\n",
    "weight_sum_per_group = torch.zeros((bsz, num_head, B_len),dtype = weight_per_A.dtype)\n",
    "weight_sum_per_group.scatter_reduce_(index = group_idx_per_A_idx, src = weight_per_A, reduce = 'sum', dim = 2 )\n",
    "\n",
    "weighted_A_per_group = weight_per_A.unsqueeze(-1).expand(-1,-1,-1, head_dim) * A \n",
    "\n",
    "weighted_sum_A_per_group = torch.zeros((bsz, num_head,B_len, head_dim))\n",
    "weighted_sum_A_per_group.scatter_reduce_(index = group_idx_per_A_idx.unsqueeze(-1).expand(-1,-1,-1, head_dim), src = weighted_A_per_group, dim = 2, reduce = 'sum' )\n",
    "\n",
    "\n",
    "weighted_mean_A_per_group = weighted_sum_A_per_group / weight_sum_per_group.unsqueeze(-1).expand(-1,-1,-1, head_dim).clamp_min(1e-12)\n",
    "\n",
    "## count the group\n",
    "count_per_group = torch.zeros_like(group_max, dtype = group_idx_per_A_idx.dtype)\n",
    "ones = torch.ones_like(group_idx_per_A_idx)\n",
    "\n",
    "count_per_group.scatter_reduce_(index = group_idx_per_A_idx, src = ones, reduce = 'sum', dim = 2)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.24"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}