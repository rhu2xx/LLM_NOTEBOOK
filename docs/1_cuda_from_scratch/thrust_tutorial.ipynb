{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0314bc9c",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Thrust Tutorial](#toc1_)    \n",
    "  - [The underlying Compilation](#toc1_1_)    \n",
    "  - [Code Explanation](#toc1_2_)    \n",
    "  - [Execution Policy vs Specifier](#toc1_3_)    \n",
    "    - [Code exercise: Compute Median Temperature](#toc1_3_1_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca65baa1",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Thrust Tutorial](#toc0_)\n",
    "\n",
    "Reference: \n",
    "[Youtube](https://www.youtube.com/watch?v=Sdjn9FOkhnA&list=PL5B692fm6--vWLhYPqLcEu6RF3hXjEyJr&index=1)\n",
    "[Colab](https://github.com/NVIDIA/accelerated-computing-hub/blob/main/tutorials/cuda-cpp/README.md)\n",
    "## <a id='toc1_1_'></a>[The underlying Compilation](#toc0_)\n",
    "\n",
    "![](Sources/compilation.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5066a1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PATH\"] = \"/usr/local/cuda/bin:\" + os.environ[\"PATH\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bbcfe4",
   "metadata": {},
   "source": [
    "## <a id='toc1_2_'></a>[Code Explanation](#toc0_)\n",
    "\n",
    "Start withe the following code:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "917c8fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Sources/cpu-cooling.cpp\n"
     ]
    }
   ],
   "source": [
    "%%writefile Sources/cpu-cooling.cpp\n",
    "\n",
    "#include <cstdio>\n",
    "#include <vector>\n",
    "#include <algorithm>\n",
    "\n",
    "int main() {\n",
    "    float k = 0.5;\n",
    "    float ambient_temp = 20;\n",
    "    std::vector<float> temp{ 42, 24, 50 };\n",
    "    \n",
    "\n",
    "    auto op = [=](float temp){\n",
    "        float diff = ambient_temp - temp;\n",
    "        return temp + k * diff;\n",
    "    };\n",
    "\n",
    "    std::printf(\"step  temp[0]  temp[1]  temp[2]\\n\");\n",
    "    for (int step = 0; step < 3; step++) {\n",
    "        \n",
    "\n",
    "        std::transform(temp.begin(), temp.end(),\n",
    "                        temp.begin(), op);\n",
    "\n",
    "        std::printf(\"%d     %.2f    %.2f    %.2f\\n\", step, temp[0], temp[1], temp[2]);\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a23352d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step  temp[0]  temp[1]  temp[2]\n",
      "0     31.00    22.00    35.00\n",
      "1     25.50    21.00    27.50\n",
      "2     22.75    20.50    23.75\n"
     ]
    }
   ],
   "source": [
    "!nvcc -x cu -arch=native Sources/cpu-cooling.cpp -o temp/a.out # compile the code\n",
    "!./temp/a.out # run the executable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ec4c88",
   "metadata": {},
   "source": [
    "We implement it at GPU side.\n",
    "\n",
    "\n",
    "`thrust::universal_vector` is a vector that can be used in both host and device side.\n",
    "Unified memory is a memory management system that allows the CPU and GPU to share a single memory space without explicit data transfers `cudaMemcpy`. In the underlying implementation, it was created using `cudaMallocManaged`. When using unified memory, the CUDA runtime automatically transfers the data whose unit is a page (typically 4KB) between the host and device as needed. But, the **synchronization** is still needed. It is UB(undefined behavior) if the data is accessed from both host and device without synchronization.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20b253f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Sources/thrust-cooling.cpp\n"
     ]
    }
   ],
   "source": [
    "%%writefile Sources/thrust-cooling.cpp\n",
    "\n",
    "#include <thrust/execution_policy.h>\n",
    "#include <thrust/universal_vector.h>\n",
    "#include <thrust/transform.h>\n",
    "#include <cstdio>\n",
    "\n",
    "int main() {\n",
    "    float k = 0.5;\n",
    "    float ambient_temp = 20;\n",
    "    thrust::universal_vector<float> temp{ 42, 24, 50 };\n",
    "    auto transformation = [=] __host__ __device__ (float temp) { return temp + k * (ambient_temp - temp); };\n",
    "\n",
    "    std::printf(\"step  temp[0]  temp[1]  temp[2]\\n\");\n",
    "    for (int step = 0; step < 3; step++) {\n",
    "        thrust::transform(thrust::device, temp.begin(), temp.end(), temp.begin(), transformation);\n",
    "        std::printf(\"%d     %.2f    %.2f    %.2f\\n\", step, temp[0], temp[1], temp[2]);\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9805d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step  temp[0]  temp[1]  temp[2]\n",
      "0     31.00    22.00    35.00\n",
      "1     25.50    21.00    27.50\n",
      "2     22.75    20.50    23.75\n"
     ]
    }
   ],
   "source": [
    "!nvcc -std=c++14 --extended-lambda Sources/thrust-cooling.cpp -x cu -arch=native -o temp/a.out # compile the code\n",
    "!./temp/a.out # run the executable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668c6ef7",
   "metadata": {},
   "source": [
    "## <a id='toc1_3_'></a>[Execution Policy vs Specifier](#toc0_)\n",
    "`Execution Plolicy`(`thrust::device`,`thrust::host`) indicates where the code will run. It doesn't automatically compile code for the location.\n",
    "\n",
    "`Execution Specifier`(`__host__`,`__device__`) indicates where the code can run. It doesn't automatically run code there.\n",
    "\n",
    "![](Sources/policyvsspecifier.png)\n",
    "![](Sources/table_policyvsspecifier.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e84702",
   "metadata": {},
   "source": [
    "### <a id='toc1_3_1_'></a>[Code exercise: Compute Median Temperature](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a993374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Sources/port-sort-to-gpu.cpp\n"
     ]
    }
   ],
   "source": [
    "%%writefile Sources/port-sort-to-gpu.cpp\n",
    "#include <thrust/execution_policy.h>\n",
    "#include <thrust/universal_vector.h>\n",
    "#include <thrust/transform.h>\n",
    "#include <cstdio>\n",
    "#include <algorithm>\n",
    "\n",
    "float median(thrust::universal_vector<float> vec)\n",
    "{\n",
    "    \n",
    "    std::sort(vec.begin(), vec.end());\n",
    "    return vec[vec.size() / 2];\n",
    "}\n",
    "\n",
    "int main(){\n",
    "    float k =0.5;\n",
    "    float ambient_temp =20;\n",
    "    thrust::universal_vector<float> temp{42,24,50};\n",
    "    auto transformation = [=] __host__ __device__ (float temp) { return temp + k * (ambient_temp - temp); };\n",
    "    std::printf(\"step  median\\n\");\n",
    "    for (int step = 0; step < 3; step++) {\n",
    "        thrust::transform(thrust::device, temp.begin(),temp.end(),\n",
    "                          temp.begin(), transformation);\n",
    "        float median_temp = median(temp);\n",
    "        std::printf(\"%d     %.2f\\n\", step, median_temp);\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50047487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step  median\n",
      "0     31.00\n",
      "1     25.50\n",
      "2     22.75\n",
      "\tCommand being timed: \"./temp/a.out\"\n",
      "\tUser time (seconds): 0.02\n",
      "\tSystem time (seconds): 0.13\n",
      "\tPercent of CPU this job got: 99%\n",
      "\tElapsed (wall clock) time (h:mm:ss or m:ss): 0:00.16\n",
      "\tAverage shared text size (kbytes): 0\n",
      "\tAverage unshared data size (kbytes): 0\n",
      "\tAverage stack size (kbytes): 0\n",
      "\tAverage total size (kbytes): 0\n",
      "\tMaximum resident set size (kbytes): 106920\n",
      "\tAverage resident set size (kbytes): 0\n",
      "\tMajor (requiring I/O) page faults: 3\n",
      "\tMinor (reclaiming a frame) page faults: 5599\n",
      "\tVoluntary context switches: 60\n",
      "\tInvoluntary context switches: 1\n",
      "\tSwaps: 0\n",
      "\tFile system inputs: 0\n",
      "\tFile system outputs: 0\n",
      "\tSocket messages sent: 0\n",
      "\tSocket messages received: 0\n",
      "\tSignals delivered: 0\n",
      "\tPage size (bytes): 4096\n",
      "\tExit status: 0\n"
     ]
    }
   ],
   "source": [
    "# !nvcc -std=c++14 --extended-lambda Sources/port-sort-to-gpu.cpp -x cu -arch=native -o temp/a.out # compile the code\n",
    "# !time -v ./temp/a.out # run the executable\n",
    "!/usr/bin/time -v ./temp/a.out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6703c51",
   "metadata": {},
   "source": [
    "## Thrust fancy iterators\n",
    "**We don't need to declare the execution policy when using fancy iterators.**\n",
    "\n",
    "Here we show three types of fancy iterators in Thrust.\n",
    "```c++\n",
    "auto begin = thrust::make_counting_iterator(1);\n",
    "auto end = begin + 10;\n",
    "thrust::for_each(begin,end,print);\n",
    "\n",
    "thrust::make_zip_iterator(a.begin(), b.begin());\n",
    "thrust::make_transform_iterator(a.begin(), \n",
    "    [] __host__ __device__ (float x) { return x * x; });\n",
    "```\n",
    "In the following code, we will implement the maximum of the change in the temperature using Thrust.\n",
    "The original step should be \n",
    "1. compute the gap between the current temperature and previous temperature `a` and `b`;\n",
    "2. compute the maximum of the gap\n",
    "\n",
    "But in this implementation, we have to read `2*n` floats total from `a` and `b`, and then store `n` floats to the temporary array `temp`. Then in the reduction step, we read `n` floats from `temp`. So the total memory access is `4*n` floats.\n",
    "\n",
    "To optimize the memory access, we can find the maximum when computing the gap, so that we don't need the temporary array `temp` to store the gap. The total memory access is `2*n` floats.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "395e7878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Sources/naive-vs-iterators.cpp\n"
     ]
    }
   ],
   "source": [
    "%%writefile Sources/naive-vs-iterators.cpp\n",
    "#include <thrust/execution_policy.h>\n",
    "#include <thrust/universal_vector.h>\n",
    "#include <thrust/transform.h>\n",
    "#include <thrust/reduce.h>\n",
    "#include <thrust/sequence.h>\n",
    "#include <cstdio>\n",
    "#include <chrono>\n",
    "\n",
    "float naive_max_change(const thrust::universal_vector<float>& a, const thrust::universal_vector<float>& b)\n",
    "{\n",
    "    thrust::universal_vector<float> diff(a.size());\n",
    "    //x = a[i];y = b[i];diff[i] = abs(x - y);\n",
    "    thrust::transform(thrust::device, a.begin(), a.end(), b.begin(), diff.begin(),\n",
    "        []__host__ __device__(float x, float y) {\n",
    "            return abs(x - y);\n",
    "        });\n",
    "    return thrust::reduce(thrust::device, diff.begin(), diff.end(), 0.0f, thrust::maximum<float>{});\n",
    "}\n",
    "\n",
    "float max_change(const thrust::universal_vector<float>& a, const thrust::universal_vector<float>& b)\n",
    "{\n",
    "    auto zip = thrust::make_zip_iterator(a.begin(), b.begin());\n",
    "    auto transform = thrust::make_transform_iterator(zip, []__host__ __device__(thrust::tuple<float, float> t) {\n",
    "        return abs(thrust::get<0>(t) - thrust::get<1>(t));\n",
    "    });\n",
    "    return thrust::reduce(thrust::device, transform, transform + a.size(), 0.0f, thrust::maximum<float>{});\n",
    "}\n",
    "\n",
    "int main()\n",
    "{\n",
    "    // allocate vectors containing 2^28 elements\n",
    "    thrust::universal_vector<float> a(1 << 28);\n",
    "    thrust::universal_vector<float> b(1 << 28);\n",
    "\n",
    "    thrust::sequence(a.begin(), a.end());\n",
    "    thrust::sequence(b.rbegin(), b.rend());\n",
    "\n",
    "    auto start_naive = std::chrono::high_resolution_clock::now();\n",
    "    naive_max_change(a, b);\n",
    "    auto end_naive = std::chrono::high_resolution_clock::now();\n",
    "    const double naive_duration = std::chrono::duration_cast<std::chrono::milliseconds>(end_naive - start_naive).count();\n",
    "\n",
    "    auto start = std::chrono::high_resolution_clock::now();\n",
    "    max_change(a, b);\n",
    "    auto end = std::chrono::high_resolution_clock::now();\n",
    "    const double duration = std::chrono::duration_cast<std::chrono::milliseconds>(end - start).count();\n",
    "\n",
    "    std::printf(\"iterators are %g times faster than naive approach\\n\", naive_duration / duration);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b6429b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterators are 95 times faster than naive approach\n"
     ]
    }
   ],
   "source": [
    "!nvcc --extended-lambda -o /tmp/a.out Sources/naive-vs-iterators.cpp -x cu -arch=native # build executable\n",
    "!/tmp/a.out # run executable"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_toy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
