{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca65baa1",
   "metadata": {},
   "source": [
    "# Thrust Tutorial\n",
    "\n",
    "Reference: \n",
    "[Youtube](https://www.youtube.com/watch?v=Sdjn9FOkhnA&list=PL5B692fm6--vWLhYPqLcEu6RF3hXjEyJr&index=1)\n",
    "[Colab](https://github.com/NVIDIA/accelerated-computing-hub/blob/main/tutorials/cuda-cpp/README.md)\n",
    "## The underlying Compilation\n",
    "\n",
    "![](Sources/compilation.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5066a1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PATH\"] = \"/usr/local/cuda/bin:\" + os.environ[\"PATH\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f29d532f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing Sources/cuda_properties.cpp\n"
     ]
    }
   ],
   "source": [
    "%%writefile Sources/cuda_properties.cpp\n",
    "#include <iostream>\n",
    "#include <cuda_runtime.h>\n",
    "\n",
    "static double max_bandwidth(cudaDeviceProp &prop) {\n",
    "\n",
    "    const std::size_t mem_freq =\n",
    "        static_cast<std::size_t>(prop.memoryClockRate) * 1000; // kHz -> Hz\n",
    "    const int bus_width = prop.memoryBusWidth;\n",
    "    const std::size_t bytes_per_second = 2 * mem_freq * bus_width / CHAR_BIT;\n",
    "    return static_cast<double>(bytes_per_second) / 1024 / 1024 /\n",
    "            1024; // B/s -> GB/s\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    int deviceCount;\n",
    "    cudaGetDeviceCount(&deviceCount);\n",
    "    for (int device = 0; device < deviceCount; ++device) {\n",
    "        cudaDeviceProp prop;\n",
    "        cudaGetDeviceProperties(&prop, device);\n",
    "        std::cout << \"Device \" << device << \": \" << prop.name << std::endl;\n",
    "        std::cout << \"  Total Global Memory: \" << prop.totalGlobalMem / (1024 * 1024) << \" MB\" << std::endl;\n",
    "        std::cout << \"  Shared Memory per Block: \" << prop.sharedMemPerBlock / 1024 << \" KB\" << std::endl;\n",
    "        std::cout << \"  Registers per Block: \" << prop.regsPerBlock << std::endl;\n",
    "        std::cout << \"  Warp Size: \" << prop.warpSize << std::endl;\n",
    "        std::cout << \"  Max Threads per Block: \" << prop.maxThreadsPerBlock << std::endl;\n",
    "        std::cout << \"  Max Threads Dimension: [\" \n",
    "                  << prop.maxThreadsDim[0] << \", \"\n",
    "                  << prop.maxThreadsDim[1] << \", \"\n",
    "                  << prop.maxThreadsDim[2] << \"]\" << std::endl;\n",
    "        std::cout << \"  Max Grid Size: [\" \n",
    "                  << prop.maxGridSize[0] << \", \"\n",
    "                  << prop.maxGridSize[1] << \", \"\n",
    "                  << prop.maxGridSize[2] << \"]\" << std::endl;\n",
    "        std::cout << \"  Total Constant Memory: \" << prop.totalConstMem / 1024 << \" KB\" << std::endl;\n",
    "        std::cout << \"  Compute Capability: \" << prop.major << \".\" << prop.minor << std::endl;\n",
    "        std::cout << \"  Max Memory Bandwidth: \" << max_bandwidth(prop) << \" GB/s\" << std::endl;\n",
    "    }\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e16a8de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device 0: NVIDIA TITAN RTX\n",
      "  Total Global Memory: 24205 MB\n",
      "  Shared Memory per Block: 48 KB\n",
      "  Registers per Block: 65536\n",
      "  Warp Size: 32\n",
      "  Max Threads per Block: 1024\n",
      "  Max Threads Dimension: [1024, 1024, 64]\n",
      "  Max Grid Size: [2147483647, 65535, 65535]\n",
      "  Total Constant Memory: 64 KB\n",
      "  Compute Capability: 7.5\n",
      "  Max Memory Bandwidth: 625.938 GB/s\n",
      "Device 1: NVIDIA TITAN RTX\n",
      "  Total Global Memory: 24205 MB\n",
      "  Shared Memory per Block: 48 KB\n",
      "  Registers per Block: 65536\n",
      "  Warp Size: 32\n",
      "  Max Threads per Block: 1024\n",
      "  Max Threads Dimension: [1024, 1024, 64]\n",
      "  Max Grid Size: [2147483647, 65535, 65535]\n",
      "  Total Constant Memory: 64 KB\n",
      "  Compute Capability: 7.5\n",
      "  Max Memory Bandwidth: 625.938 GB/s\n"
     ]
    }
   ],
   "source": [
    "!nvcc --extended-lambda -o /tmp/cuda_properties.out Sources/cuda_properties.cpp -x cu -arch=native # build executable\n",
    "!/tmp/cuda_properties.out # run executable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bbcfe4",
   "metadata": {},
   "source": [
    "## Code Explanation\n",
    "\n",
    "Start withe the following code:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "917c8fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Sources/cpu-cooling.cpp\n"
     ]
    }
   ],
   "source": [
    "%%writefile Sources/cpu-cooling.cpp\n",
    "\n",
    "#include <cstdio>\n",
    "#include <vector>\n",
    "#include <algorithm>\n",
    "\n",
    "int main() {\n",
    "    float k = 0.5;\n",
    "    float ambient_temp = 20;\n",
    "    std::vector<float> temp{ 42, 24, 50 };\n",
    "    \n",
    "\n",
    "    auto op = [=](float temp){\n",
    "        float diff = ambient_temp - temp;\n",
    "        return temp + k * diff;\n",
    "    };\n",
    "\n",
    "    std::printf(\"step  temp[0]  temp[1]  temp[2]\\n\");\n",
    "    for (int step = 0; step < 3; step++) {\n",
    "        \n",
    "\n",
    "        std::transform(temp.begin(), temp.end(),\n",
    "                        temp.begin(), op);\n",
    "\n",
    "        std::printf(\"%d     %.2f    %.2f    %.2f\\n\", step, temp[0], temp[1], temp[2]);\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a23352d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step  temp[0]  temp[1]  temp[2]\n",
      "0     31.00    22.00    35.00\n",
      "1     25.50    21.00    27.50\n",
      "2     22.75    20.50    23.75\n"
     ]
    }
   ],
   "source": [
    "!nvcc -x cu -arch=native Sources/cpu-cooling.cpp -o temp/a.out # compile the code\n",
    "!./temp/a.out # run the executable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ec4c88",
   "metadata": {},
   "source": [
    "We implement it at GPU side.\n",
    "\n",
    "\n",
    "`thrust::universal_vector` is a vector that can be used in both host and device side.\n",
    "Unified memory is a memory management system that allows the CPU and GPU to share a single memory space without explicit data transfers `cudaMemcpy`. In the underlying implementation, it was created using `cudaMallocManaged`. When using unified memory, the CUDA runtime automatically transfers the data whose unit is a page (typically 4KB) between the host and device as needed. But, the **synchronization** is still needed. It is UB(undefined behavior) if the data is accessed from both host and device without synchronization.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20b253f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Sources/thrust-cooling.cpp\n"
     ]
    }
   ],
   "source": [
    "%%writefile Sources/thrust-cooling.cpp\n",
    "\n",
    "#include <thrust/execution_policy.h>\n",
    "#include <thrust/universal_vector.h>\n",
    "#include <thrust/transform.h>\n",
    "#include <cstdio>\n",
    "\n",
    "int main() {\n",
    "    float k = 0.5;\n",
    "    float ambient_temp = 20;\n",
    "    thrust::universal_vector<float> temp{ 42, 24, 50 };\n",
    "    auto transformation = [=] __host__ __device__ (float temp) { return temp + k * (ambient_temp - temp); };\n",
    "\n",
    "    std::printf(\"step  temp[0]  temp[1]  temp[2]\\n\");\n",
    "    for (int step = 0; step < 3; step++) {\n",
    "        thrust::transform(thrust::device, temp.begin(), temp.end(), temp.begin(), transformation);\n",
    "        std::printf(\"%d     %.2f    %.2f    %.2f\\n\", step, temp[0], temp[1], temp[2]);\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9805d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step  temp[0]  temp[1]  temp[2]\n",
      "0     31.00    22.00    35.00\n",
      "1     25.50    21.00    27.50\n",
      "2     22.75    20.50    23.75\n"
     ]
    }
   ],
   "source": [
    "!nvcc -std=c++14 --extended-lambda Sources/thrust-cooling.cpp -x cu -arch=native -o temp/a.out # compile the code\n",
    "!./temp/a.out # run the executable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668c6ef7",
   "metadata": {},
   "source": [
    "## Execution Policy vs Specifier\n",
    "`Execution Plolicy`(`thrust::device`,`thrust::host`) indicates where the code will run. It doesn't automatically compile code for the location.\n",
    "\n",
    "`Execution Specifier`(`__host__`,`__device__`) indicates where the code can run. It doesn't automatically run code there.\n",
    "\n",
    "![](https://github.com/rhu2xx/picx-images-hosting/raw/master/20260129/table_policyvsspecifier.2h8te16cn1.webp)\n",
    "![](https://github.com/rhu2xx/picx-images-hosting/raw/master/20260129/policyvsspecifier.3rbqkcojo5.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e84702",
   "metadata": {},
   "source": [
    "### Code exercise: Compute Median Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a993374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Sources/port-sort-to-gpu.cpp\n"
     ]
    }
   ],
   "source": [
    "%%writefile Sources/port-sort-to-gpu.cpp\n",
    "#include <thrust/execution_policy.h>\n",
    "#include <thrust/universal_vector.h>\n",
    "#include <thrust/transform.h>\n",
    "#include <cstdio>\n",
    "#include <algorithm>\n",
    "\n",
    "float median(thrust::universal_vector<float> vec)\n",
    "{\n",
    "    \n",
    "    std::sort(vec.begin(), vec.end());\n",
    "    return vec[vec.size() / 2];\n",
    "}\n",
    "\n",
    "int main(){\n",
    "    float k =0.5;\n",
    "    float ambient_temp =20;\n",
    "    thrust::universal_vector<float> temp{42,24,50};\n",
    "    auto transformation = [=] __host__ __device__ (float temp) { return temp + k * (ambient_temp - temp); };\n",
    "    std::printf(\"step  median\\n\");\n",
    "    for (int step = 0; step < 3; step++) {\n",
    "        thrust::transform(thrust::device, temp.begin(),temp.end(),\n",
    "                          temp.begin(), transformation);\n",
    "        float median_temp = median(temp);\n",
    "        std::printf(\"%d     %.2f\\n\", step, median_temp);\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50047487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step  median\n",
      "0     31.00\n",
      "1     25.50\n",
      "2     22.75\n",
      "\tCommand being timed: \"./temp/a.out\"\n",
      "\tUser time (seconds): 0.02\n",
      "\tSystem time (seconds): 0.13\n",
      "\tPercent of CPU this job got: 99%\n",
      "\tElapsed (wall clock) time (h:mm:ss or m:ss): 0:00.16\n",
      "\tAverage shared text size (kbytes): 0\n",
      "\tAverage unshared data size (kbytes): 0\n",
      "\tAverage stack size (kbytes): 0\n",
      "\tAverage total size (kbytes): 0\n",
      "\tMaximum resident set size (kbytes): 106920\n",
      "\tAverage resident set size (kbytes): 0\n",
      "\tMajor (requiring I/O) page faults: 3\n",
      "\tMinor (reclaiming a frame) page faults: 5599\n",
      "\tVoluntary context switches: 60\n",
      "\tInvoluntary context switches: 1\n",
      "\tSwaps: 0\n",
      "\tFile system inputs: 0\n",
      "\tFile system outputs: 0\n",
      "\tSocket messages sent: 0\n",
      "\tSocket messages received: 0\n",
      "\tSignals delivered: 0\n",
      "\tPage size (bytes): 4096\n",
      "\tExit status: 0\n"
     ]
    }
   ],
   "source": [
    "# !nvcc -std=c++14 --extended-lambda Sources/port-sort-to-gpu.cpp -x cu -arch=native -o temp/a.out # compile the code\n",
    "# !time -v ./temp/a.out # run the executable\n",
    "!/usr/bin/time -v ./temp/a.out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6703c51",
   "metadata": {},
   "source": [
    "## Thrust fancy iterators\n",
    "**We don't need to declare the execution policy when using fancy iterators.**\n",
    "\n",
    "Here we show three types of fancy iterators in Thrust.\n",
    "```c++\n",
    "auto begin = thrust::make_counting_iterator(1);\n",
    "auto end = begin + 10;\n",
    "thrust::for_each(begin,end,print);\n",
    "\n",
    "thrust::make_zip_iterator(a.begin(), b.begin());\n",
    "thrust::make_transform_iterator(a.begin(), \n",
    "    [] __host__ __device__ (float x) { return x * x; });\n",
    "```\n",
    "In the following code, we will implement the maximum of the change in the temperature using Thrust.\n",
    "The original step should be \n",
    "1. compute the gap between the current temperature and previous temperature `a` and `b`;\n",
    "2. compute the maximum of the gap\n",
    "\n",
    "But in this implementation, we have to read `2*n` floats total from `a` and `b`, and then store `n` floats to the temporary array `temp`. Then in the reduction step, we read `n` floats from `temp`. So the total memory access is `4*n` floats.\n",
    "\n",
    "To optimize the memory access, we can find the maximum when computing the gap, so that we don't need the temporary array `temp` to store the gap. The total memory access is `2*n` floats.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395e7878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Sources/naive-vs-iterators.cpp\n"
     ]
    }
   ],
   "source": [
    "%%writefile Sources/naive-vs-iterators.cpp\n",
    "#include <thrust/execution_policy.h>\n",
    "#include <thrust/universal_vector.h>\n",
    "#include <thrust/transform.h>\n",
    "#include <thrust/reduce.h>\n",
    "#include <thrust/sequence.h>\n",
    "#include <cstdio>\n",
    "#include <chrono>\n",
    "\n",
    "float naive_max_change(const thrust::universal_vector<float>& a, const thrust::universal_vector<float>& b)\n",
    "{\n",
    "    thrust::universal_vector<float> diff(a.size());\n",
    "    //x = a[i];y = b[i];diff[i] = abs(x - y);\n",
    "    thrust::transform(thrust::device, a.begin(), a.end(), b.begin(), diff.begin(),\n",
    "        []__host__ __device__(float x, float y) {\n",
    "            return abs(x - y);\n",
    "        });\n",
    "    return thrust::reduce(thrust::device, diff.begin(), diff.end(), 0.0f, thrust::maximum<float>{});\n",
    "}\n",
    "\n",
    "float max_change(const thrust::universal_vector<float>& a, const thrust::universal_vector<float>& b)\n",
    "{\n",
    "    auto zip = thrust::make_zip_iterator(a.begin(), b.begin());\n",
    "    auto transform = thrust::make_transform_iterator(zip, []__host__ __device__(thrust::tuple<float, float> t) {\n",
    "        return abs(thrust::get<0>(t) - thrust::get<1>(t));\n",
    "    });\n",
    "    return thrust::reduce(thrust::device, transform, transform + a.size(), 0.0f, thrust::maximum<float>{});\n",
    "}\n",
    "\n",
    "int main()\n",
    "{\n",
    "    // allocate vectors containing 2^28 elements\n",
    "    thrust::universal_vector<float> a(1 << 28);\n",
    "    thrust::universal_vector<float> b(1 << 28);\n",
    "\n",
    "    thrust::sequence(a.begin(), a.end());\n",
    "    thrust::sequence(b.rbegin(), b.rend());\n",
    "\n",
    "    auto start_naive = std::chrono::high_resolution_clock::now();\n",
    "    naive_max_change(a, b);\n",
    "    auto end_naive = std::chrono::high_resolution_clock::now();\n",
    "    const double naive_duration = std::chrono::duration_cast<std::chrono::milliseconds>(end_naive - start_naive).count();\n",
    "\n",
    "    auto start = std::chrono::high_resolution_clock::now();\n",
    "    max_change(a, b);\n",
    "    auto end = std::chrono::high_resolution_clock::now();\n",
    "    const double duration = std::chrono::duration_cast<std::chrono::milliseconds>(end - start).count();\n",
    "\n",
    "    std::printf(\"iterators are %g times faster than naive approach\\n\", naive_duration / duration);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b6429b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterators are 95 times faster than naive approach\n"
     ]
    }
   ],
   "source": [
    "!nvcc --extended-lambda -o /tmp/a.out Sources/naive-vs-iterators.cpp -x cu -arch=native # build executable\n",
    "!/tmp/a.out # run executable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512f2a94",
   "metadata": {},
   "source": [
    "## Tabulate\n",
    "\n",
    "Here, we implement a heat transfer simulation using the tabulate iterator to compute the temperature at each point based on its neighbors.\n",
    "\n",
    "`thrust::tabulate` is the equivalent of transformation of the counting iterator.\n",
    "\n",
    "> in `thrust::transform`, the object of `op` is the value of the input iterator.\n",
    "> in `thrust::tabulate`, the object of `op` is the index of the output iterator.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe7ce51",
   "metadata": {},
   "outputs": [],
   "source": [
    "// navie version\n",
    "#include <cuda/std/mdspan>\n",
    "\n",
    "// extract the row and column idx\n",
    "__host__ __device__\n",
    "cuda::std::pair<int, int> row_col(int id, int width){\n",
    "    return cuda::std::make_pair(id / width, id % width);\n",
    "}\n",
    "\n",
    "void simulate(\n",
    "    int height, int width,\n",
    "    const thrust::universal_vector<float> &in,\n",
    "    thrust::universal_vector<float> &out\n",
    "){\n",
    "    const float *in_ptr = thrust::raw_pointer_cast(in.data()); // get the raw memory pointer\n",
    "    auto cell_indices = thrust::make_counting_iterator(0);\n",
    "    thrust::transform(\n",
    "        thrust::device, cell_indices, cell_indices + in.size(), out.begin(),\n",
    "        [in_ptr, height, width] __host__ __device__ (int id){\n",
    "            auto [row, col] = row_col(id, width);\n",
    "            // boundary check\n",
    "            if (row > 0 && col > 0 && row < height - 1 && col < width - 1) {\n",
    "                float d2tdx2 = in_ptr[(row) * width + col - 1] - 2 * in_ptr[row * width + col] + in_ptr[(row) * width + col + 1];\n",
    "                float d2tdy2 = in_ptr[(row - 1) * width + col] - 2 * in_ptr[row * width + col] + in_ptr[(row + 1) * width + col];\n",
    "\n",
    "                return in_ptr[row * width + column] + 0.2f * (d2tdx2 + d2tdy2);\n",
    "            } else {\n",
    "                return in_ptr[row * width + column];\n",
    "            }\n",
    "        }\n",
    "    );\n",
    "\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a726c3",
   "metadata": {},
   "source": [
    "To clarify this function, we use `thrust::tabulate` to replace the `thrust::transform` and delete the temporary iterator `thrust::make_counting_iterator(0)`.\n",
    "\n",
    "```c++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed5ad5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "// tabulate version\n",
    "#include <thrust/tabulate.h>\n",
    "\n",
    "void simulate(\n",
    "    int height, int width,\n",
    "    const thrust::universal_vector<float> &in,\n",
    "    thrust::universal_vector<float> &out\n",
    "){\n",
    "    const float *in_ptr = thrust::raw_pointer_cast(in.data()); // get the raw memory pointer\n",
    "    thrust::tabulate(\n",
    "        thrust::device, out.begin(), out.end(),\n",
    "        [in_ptr, height, width] __host__ __device__ (int id){\n",
    "            auto [row, col] = row_col(id, width);\n",
    "            // boundary check\n",
    "            if (row > 0 && col > 0 && row < height - 1 && col < width - 1) {\n",
    "                float d2tdx2 = in_ptr[(row) * width + col - 1] - 2 * in_ptr[row * width + col] + in_ptr[(row) * width + col + 1];\n",
    "                float d2tdy2 = in_ptr[(row - 1) * width + col] - 2 * in_ptr[row * width + col] + in_ptr[(row + 1) * width + col];\n",
    "\n",
    "                return in_ptr[row * width + col] + 0.2f * (d2tdx2 + d2tdy2);\n",
    "            } else {\n",
    "                return in_ptr[row * width + col];\n",
    "            }\n",
    "        }\n",
    "    );\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870a3e8e",
   "metadata": {},
   "source": [
    "### `cuda::std::mdspan` for multi-dimensional array view\n",
    "\n",
    "![](https://github.com/rhu2xx/picx-images-hosting/raw/master/20260129/image.96a92s74w0.webp)\n",
    "\n",
    "Notice that we use `row_col` to conver the 1D index to 2D index. This is because Thrust doesn't support multi-dimensional array view. We can use `thrust::mdspan` to achieve this.\n",
    "\n",
    "**syntax:**\n",
    "```c++\n",
    "cuda::std::mdspan md(pointer, extent0, extent1, ...);\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4dc59f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Sources/mdspan.cpp\n"
     ]
    }
   ],
   "source": [
    "%%writefile Sources/mdspan.cpp\n",
    "#include <cuda/std/mdspan>\n",
    "#include <cuda/std/array>\n",
    "#include <thrust/device_ptr.h>\n",
    "#include <cstdio>\n",
    "int main() {\n",
    "  cuda::std::array<int, 6> sd {0, 1, 2, 3, 4, 5};\n",
    "  std::printf(\"type of sd.data(): %s\\n\", typeid(sd.data()).name()); // type of sd.data(): Pi i.e., pointer to int\n",
    "  std::printf(\"type of sd.data(): %s\\n\", typeid(thrust::raw_pointer_cast(sd.data())).name());\n",
    "\n",
    "  // cuda::std::mdspan md(sd.data(), 2, 3);\n",
    "  cuda::std::mdspan md(thrust::raw_pointer_cast(sd.data()), 2, 3);\n",
    "  std::printf(\"type of md(): %s\\n\", typeid(md).name()); \n",
    "  std::printf(\"md(0, 0) = %d\\n\", md(0, 0)); // 0\n",
    "  std::printf(\"md(1, 2) = %d\\n\", md(1, 2)); // 5\n",
    "\n",
    "  std::printf(\"size   = %zu\\n\", md.size());    // 6\n",
    "  std::printf(\"height = %zu\\n\", md.extent(0)); // 2\n",
    "  std::printf(\"width  = %zu\\n\", md.extent(1)); // 3\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac1eb607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of sd.data(): Pi\n",
      "type of sd.data(): Pi\n",
      "type of md(): N4cuda3std3__46mdspanIiNS1_7extentsImJLm18446744073709551615ELm18446744073709551615EEEENS1_12layout_rightENS1_16default_accessorIiEEEE\n",
      "md(0, 0) = 0\n",
      "md(1, 2) = 5\n",
      "size   = 6\n",
      "height = 2\n",
      "width  = 3\n"
     ]
    }
   ],
   "source": [
    "!nvcc --extended-lambda -o /tmp/a.out Sources/mdspan.cpp -x cu -arch=native # build executable\n",
    "!/tmp/a.out # run executable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68a80e7",
   "metadata": {},
   "source": [
    "## Serial Vs Parallel\n",
    "\n",
    "![](https://github.com/rhu2xx/picx-images-hosting/raw/master/20260129/image.7axoa5t3w3.webp)\n",
    "\n",
    "### Segmented Summarization\n",
    "We use the example of row reduction to illustrate the difference between serial and parallel execution.\n",
    "\n",
    "First we show the naive serial implementation.\n",
    "We use transform to compute the reduction of each row (segment) one by one. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1c114e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Sources/naive-segmented-sum.cpp\n"
     ]
    }
   ],
   "source": [
    "%%writefile Sources/naive-segmented-sum.cpp\n",
    "#include <cstdio>\n",
    "#include <chrono>\n",
    "\n",
    "#include <thrust/tabulate.h>\n",
    "#include <thrust/execution_policy.h>\n",
    "#include <thrust/universal_vector.h>\n",
    "\n",
    "thrust::universal_vector<float> row_temperatures(\n",
    "    int height, int width,\n",
    "    const thrust::universal_vector<float>& temp)\n",
    "{\n",
    "    // allocate vector to store sums\n",
    "    thrust::universal_vector<float> sums(height);\n",
    "\n",
    "    // take raw pointer to `temp`\n",
    "    const float *d_temp_ptr = thrust::raw_pointer_cast(temp.data());\n",
    "\n",
    "    // compute row sum\n",
    "    thrust::tabulate(thrust::device, sums.begin(), sums.end(), [=]__host__ __device__(int row_id) {\n",
    "        float sum = 0;\n",
    "        for (int i = 0; i < width; i++) {\n",
    "            sum += d_temp_ptr[row_id * width + i];\n",
    "        }\n",
    "        return sum;\n",
    "    });\n",
    "\n",
    "    return sums;\n",
    "}\n",
    "\n",
    "thrust::universal_vector<float> init(int height, int width) {\n",
    "    const float low = 15.0;\n",
    "    const float high = 90.0;\n",
    "    thrust::universal_vector<float> temp(height * width, low);\n",
    "    thrust::fill(thrust::device, temp.begin(), temp.begin() + width, high);\n",
    "    return temp;\n",
    "}\n",
    "\n",
    "int main()\n",
    "{\n",
    "    int height = 16;\n",
    "    int width = 16777216;\n",
    "    thrust::universal_vector<float> temp = init(height, width);\n",
    "\n",
    "    auto begin = std::chrono::high_resolution_clock::now();\n",
    "    thrust::universal_vector<float> sums = row_temperatures(height, width, temp);\n",
    "    auto end = std::chrono::high_resolution_clock::now();\n",
    "    const double seconds = std::chrono::duration<double>(end - begin).count();\n",
    "    const double gigabytes = static_cast<double>(temp.size() * sizeof(float)) / 1024 / 1024 / 1024;\n",
    "    const double throughput = gigabytes / seconds;\n",
    "\n",
    "    std::printf(\"computed in %g s\\n\", seconds);\n",
    "    std::printf(\"achieved throughput: %g GB/s\\n\", throughput);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe9a0cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed in 0.466818 s\n",
      "achieved throughput: 2.14216 GB/s\n"
     ]
    }
   ],
   "source": [
    "!nvcc --extended-lambda -o /tmp/a.out Sources/naive-segmented-sum.cpp -x cu -arch=native # build executable\n",
    "!/tmp/a.out # run executable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c1d956",
   "metadata": {},
   "source": [
    "To avoid manual loop, we can use `thrust::reduce_by_key` to implement the segmented reduction in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b012346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Sources/reduction-segmented-sum.cpp\n"
     ]
    }
   ],
   "source": [
    "%%writefile Sources/reduction-segmented-sum.cpp\n",
    "#include <cstdio>\n",
    "#include <chrono>\n",
    "\n",
    "#include <thrust/tabulate.h>\n",
    "#include <thrust/iterator/discard_iterator.h>\n",
    "#include <thrust/execution_policy.h>\n",
    "#include <thrust/universal_vector.h>\n",
    "\n",
    "thrust::universal_vector<float> row_temperatures(\n",
    "    int height, int width,\n",
    "    thrust::universal_vector<float>& temp)\n",
    "{\n",
    "    thrust::universal_vector<int> row_ids(height * width);\n",
    "    thrust::tabulate(thrust::device, row_ids.begin(), row_ids.end(),[width]__host__ __device__(int i) { \n",
    "        return i / width; \n",
    "    });\n",
    "    \n",
    "    thrust::universal_vector<float> sums(height);\n",
    "    thrust::reduce_by_key(\n",
    "        thrust::device,\n",
    "        row_ids.begin(), row_ids.end(),   // input keys\n",
    "        temp.begin(),                     // input values\n",
    "        thrust::make_discard_iterator(),  // output keys\n",
    "        sums.begin());                    // output values\n",
    "\n",
    "    return sums;\n",
    "}\n",
    "\n",
    "thrust::universal_vector<float> init(int height, int width) {\n",
    "    const float low = 15.0;\n",
    "    const float high = 90.0;\n",
    "    thrust::universal_vector<float> temp(height * width, low);\n",
    "    thrust::fill(thrust::device, temp.begin(), temp.begin() + width, high);\n",
    "    return temp;\n",
    "}\n",
    "\n",
    "int main()\n",
    "{\n",
    "    int height = 16;\n",
    "    int width = 16777216;\n",
    "    thrust::universal_vector<float> temp = init(height, width);\n",
    "\n",
    "    auto begin = std::chrono::high_resolution_clock::now();\n",
    "    thrust::universal_vector<float> sums = row_temperatures(height, width, temp);\n",
    "    auto end = std::chrono::high_resolution_clock::now();\n",
    "    const double seconds = std::chrono::duration<double>(end - begin).count();\n",
    "    const double gigabytes = static_cast<double>(temp.size() * sizeof(float)) / 1024 / 1024 / 1024;\n",
    "    const double throughput = gigabytes / seconds;\n",
    "\n",
    "    std::printf(\"computed in %g s\\n\", seconds);\n",
    "    std::printf(\"achieved throughput: %g GB/s\\n\", throughput);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b40436b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed in 0.244539 s\n",
      "achieved throughput: 4.08933 GB/s\n"
     ]
    }
   ],
   "source": [
    "!nvcc --extended-lambda -o /tmp/a.out Sources/reduction-segmented-sum.cpp -x cu -arch=native # build executable\n",
    "!/tmp/a.out # run executable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d2c926",
   "metadata": {},
   "source": [
    "Even though we explicitly avoid the for loop, we introduce the overhead of `row_ids` array to store the row indices. This array is of size `num_rows * num_cols`, which can be very large when the matrix is large. \n",
    "\n",
    "To optimize the memory usage, we can use `thrust::make_transform_iterator` to generate the row indices on the fly instead of storing them in an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "351cc7ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing Sources/reduction-segmented-sum-op.cpp\n"
     ]
    }
   ],
   "source": [
    "%%writefile Sources/reduction-segmented-sum-op.cpp\n",
    "#include <cstdio>\n",
    "#include <chrono>\n",
    "\n",
    "#include <thrust/tabulate.h>\n",
    "#include <thrust/iterator/discard_iterator.h>\n",
    "#include <thrust/execution_policy.h>\n",
    "#include <thrust/universal_vector.h>\n",
    "\n",
    "thrust::universal_vector<float> row_temperatures(\n",
    "    int height, int width,\n",
    "    thrust::universal_vector<float>& temp)\n",
    "{\n",
    "    auto row_ids_begin = thrust::make_transform_iterator(\n",
    "        thrust::make_counting_iterator(0),\n",
    "        [width]__host__ __device__ (int idx){\n",
    "        return idx/width;\n",
    "    });\n",
    "    auto row_ids_end = row_ids_begin + temp.size();\n",
    "    \n",
    "    thrust::universal_vector<float> sums(height);\n",
    "    thrust::reduce_by_key(\n",
    "        thrust::device,\n",
    "        row_ids_begin, row_ids_end,   // input keys\n",
    "        temp.begin(),                     // input values\n",
    "        thrust::make_discard_iterator(),  // output keys\n",
    "        sums.begin());                    // output values\n",
    "\n",
    "    return sums;\n",
    "}\n",
    "\n",
    "thrust::universal_vector<float> init(int height, int width) {\n",
    "    const float low = 15.0;\n",
    "    const float high = 90.0;\n",
    "    thrust::universal_vector<float> temp(height * width, low);\n",
    "    thrust::fill(thrust::device, temp.begin(), temp.begin() + width, high);\n",
    "    return temp;\n",
    "}\n",
    "\n",
    "int main()\n",
    "{\n",
    "    int height = 16;\n",
    "    int width = 16777216;\n",
    "    thrust::universal_vector<float> temp = init(height, width);\n",
    "\n",
    "    auto begin = std::chrono::high_resolution_clock::now();\n",
    "    thrust::universal_vector<float> sums = row_temperatures(height, width, temp);\n",
    "    auto end = std::chrono::high_resolution_clock::now();\n",
    "    const double seconds = std::chrono::duration<double>(end - begin).count();\n",
    "    const double gigabytes = static_cast<double>(temp.size() * sizeof(float)) / 1024 / 1024 / 1024;\n",
    "    const double throughput = gigabytes / seconds;\n",
    "\n",
    "    std::printf(\"computed in %g s\\n\", seconds);\n",
    "    std::printf(\"achieved throughput: %g GB/s\\n\", throughput);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4050395e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed in 0.0032395 s\n",
      "achieved throughput: 308.689 GB/s\n"
     ]
    }
   ],
   "source": [
    "!nvcc --extended-lambda -o /tmp/a.out Sources/reduction-segmented-sum-op.cpp -x cu -arch=native # build executable\n",
    "!/tmp/a.out # run executable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75570481",
   "metadata": {},
   "source": [
    "### Sgemented Mean\n",
    "To compute the segmented mean, we can first compute the segmented sum and then divide each sum by the number of elements in each segment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cd24587c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Sources/reduction-segmented-mean.cpp\n"
     ]
    }
   ],
   "source": [
    "%%writefile Sources/reduction-segmented-mean.cpp\n",
    "#include <cstdio>\n",
    "#include <chrono>\n",
    "\n",
    "#include <thrust/tabulate.h>\n",
    "#include <thrust/iterator/discard_iterator.h>\n",
    "#include <thrust/execution_policy.h>\n",
    "#include <thrust/universal_vector.h>\n",
    "\n",
    "struct mean_functor {\n",
    "    int width;\n",
    "    __host__ __device__ float operator()(float sum) const {\n",
    "        return sum / width;\n",
    "    }\n",
    "};\n",
    "\n",
    "\n",
    "thrust::universal_vector<float> row_temperatures_mean(\n",
    "    int height, int width,\n",
    "    thrust::universal_vector<float>& temp)\n",
    "{\n",
    "    thrust::universal_vector<int> means(height);\n",
    "    auto row_ids_begin = thrust::make_transform_iterator(\n",
    "        thrust::make_counting_iterator(0),\n",
    "        [width]__host__ __device__ (int idx){\n",
    "        return idx/width;\n",
    "    });\n",
    "    auto row_ids_end = row_ids_begin + temp.size();\n",
    "    // compute the summation first\n",
    "    thrust::reduce_by_key(\n",
    "        thrust::device,\n",
    "        row_ids_begin, row_ids_end,   // input keys\n",
    "        temp.begin(),                     // input values\n",
    "        thrust::make_discard_iterator(),  // output keys\n",
    "        means.begin());                    // output values\n",
    "    // then divide each sum by width to get the mean\n",
    "    thrust::transform(\n",
    "        thrust::device,\n",
    "        means.begin(), means.end(),\n",
    "        means.begin(),\n",
    "        mean_functor{width}\n",
    "    );\n",
    "    return means;\n",
    "}\n",
    "\n",
    "thrust::universal_vector<float> init(int height, int width) {\n",
    "    const float low = 15.0;\n",
    "    const float high = 90.0;\n",
    "    thrust::universal_vector<float> temp(height * width, low);\n",
    "    thrust::fill(thrust::device, temp.begin(), temp.begin() + width, high);\n",
    "    return temp;\n",
    "}\n",
    "\n",
    "int main()\n",
    "{\n",
    "    int height = 16;\n",
    "    int width = 16777216;\n",
    "    thrust::universal_vector<float> temp = init(height, width);\n",
    "\n",
    "    auto begin = std::chrono::high_resolution_clock::now();\n",
    "    thrust::universal_vector<float> means = row_temperatures_mean(height, width, temp);\n",
    "    auto end = std::chrono::high_resolution_clock::now();\n",
    "    const double seconds = std::chrono::duration<double>(end - begin).count();\n",
    "    const double gigabytes = static_cast<double>(temp.size() * sizeof(float)) / 1024 / 1024 / 1024;\n",
    "    const double throughput = gigabytes / seconds;\n",
    "\n",
    "    std::printf(\"computed in %g s\\n\", seconds);\n",
    "    std::printf(\"achieved throughput: %g GB/s\\n\", throughput);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c47eef65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed in 0.00418439 s\n",
      "achieved throughput: 238.983 GB/s\n"
     ]
    }
   ],
   "source": [
    "!nvcc --extended-lambda -o /tmp/a.out Sources/reduction-segmented-mean.cpp -x cu -arch=native # build executable\n",
    "! /tmp/a.out # run executable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1873c4f",
   "metadata": {},
   "source": [
    "We can fuse the two steps into one step using `make_transform_output_iterator` after the segmented sum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1e3088be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Sources/reduction-segmented-mean.cpp\n"
     ]
    }
   ],
   "source": [
    "%%writefile Sources/reduction-segmented-mean.cpp\n",
    "#include <cstdio>\n",
    "#include <chrono>\n",
    "\n",
    "#include <thrust/tabulate.h>\n",
    "#include <thrust/iterator/discard_iterator.h>\n",
    "#include <thrust/iterator/transform_output_iterator.h>\n",
    "#include <thrust/execution_policy.h>\n",
    "#include <thrust/universal_vector.h>\n",
    "\n",
    "struct mean_functor {\n",
    "    int width;\n",
    "    //! `()` : \n",
    "    __host__ __device__ float operator()(float sum) const {\n",
    "        return sum / width;\n",
    "    }\n",
    "};\n",
    "\n",
    "\n",
    "thrust::universal_vector<float> row_temperatures_mean(\n",
    "    int height, int width,\n",
    "    thrust::universal_vector<float>& temp)\n",
    "{\n",
    "    thrust::universal_vector<int> means(height);\n",
    "    auto row_ids_begin = thrust::make_transform_iterator(\n",
    "        thrust::make_counting_iterator(0),\n",
    "        [width]__host__ __device__ (int idx){\n",
    "        return idx/width;\n",
    "    });\n",
    "    auto means_output_iterator = thrust::make_transform_output_iterator(\n",
    "        means.begin(),\n",
    "        mean_functor{width}\n",
    "    );\n",
    "    auto row_ids_end = row_ids_begin + temp.size();\n",
    "\n",
    "    thrust::reduce_by_key(\n",
    "        thrust::device,\n",
    "        row_ids_begin, row_ids_end,   // input keys\n",
    "        temp.begin(),                     // input values\n",
    "        thrust::make_discard_iterator(),  // output keys\n",
    "        means_output_iterator);                    // output values\n",
    "\n",
    "    return means;\n",
    "}\n",
    "\n",
    "thrust::universal_vector<float> init(int height, int width) {\n",
    "    const float low = 15.0;\n",
    "    const float high = 90.0;\n",
    "    thrust::universal_vector<float> temp(height * width, low);\n",
    "    thrust::fill(thrust::device, temp.begin(), temp.begin() + width, high);\n",
    "    return temp;\n",
    "}\n",
    "\n",
    "int main()\n",
    "{\n",
    "    int height = 16;\n",
    "    int width = 16777216;\n",
    "    thrust::universal_vector<float> temp = init(height, width);\n",
    "\n",
    "    auto begin = std::chrono::high_resolution_clock::now();\n",
    "    thrust::universal_vector<float> means = row_temperatures_mean(height, width, temp);\n",
    "    auto end = std::chrono::high_resolution_clock::now();\n",
    "    const double seconds = std::chrono::duration<double>(end - begin).count();\n",
    "    const double gigabytes = static_cast<double>(temp.size() * sizeof(float)) / 1024 / 1024 / 1024;\n",
    "    const double throughput = gigabytes / seconds;\n",
    "\n",
    "    std::printf(\"computed in %g s\\n\", seconds);\n",
    "    std::printf(\"achieved throughput: %g GB/s\\n\", throughput);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "40a46df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computed in 0.00330412 s\n",
      "achieved throughput: 302.652 GB/s\n"
     ]
    }
   ],
   "source": [
    "!nvcc --extended-lambda -o /tmp/a.out Sources/reduction-segmented-mean-op.cpp -x cu -arch=native # build executable\n",
    "! /tmp/a.out # run executable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190330fb",
   "metadata": {},
   "source": [
    "### Sgemented Reduction with Custom Binary Operator\n",
    "\n",
    "In the following code, we show how to use custom binary operator in the segmented reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2779ed77",
   "metadata": {
    "vscode": {
     "languageId": "cpp"
    }
   },
   "outputs": [],
   "source": [
    "struct functor {\n",
    "    __host__ __device__ \n",
    "    float operator()(float value_about_to_be_stored_in_output_sequence) const \n",
    "    { \n",
    "        // will store value / 2 in the output sequence instead of the original value\n",
    "        return value_about_to_be_stored_in_output_sequence / 2; \n",
    "    }\n",
    "};\n",
    "\n",
    "auto transform_output_it = \n",
    "    thrust::make_transform_output_iterator(\n",
    "        // iterator to the beginning of the output sequence\n",
    "        vector.begin(), \n",
    "        // functor to apply to value before it's written to the `vector`\n",
    "        functor{});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28192625",
   "metadata": {},
   "source": [
    "## Host and Device Memory\n",
    "\n",
    "\n",
    "Even though `thrust::universal_vector` can be used in both host and device, it is recommended to use `thrust::host_vector` and `thrust::device_vector` for better performance and memory management.\n",
    "\n",
    "When we use `thrust::universal_vector` alternatively on host and device, we need to synchronize the memory using `cudaDeviceSynchronize()` after each use on device or host to avoid undefined behavior which is implicitly required. This operation can be expensive and may lead to performance degradation.\n",
    "\n",
    "```c++\n",
    "thrust::copy(src_vector.begin(), src_vector.end(), dst_vector.begin());\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_toy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
